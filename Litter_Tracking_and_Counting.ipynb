{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPh92CWwA4Tte6PHkWZsmUX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Projectmte2023/tankbot_one/blob/main/Litter_Tracking_and_Counting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DETECTING,TRACKING AND COUNTING THE LITTER**\n",
        "\n",
        "Developed with reference to the ‘notebooks/how-to-track-and-count-vehicles-with-yolov8.ipynb’ notebook from the github repository from Roboflow https://github.com/roboflow/notebooks"
      ],
      "metadata": {
        "id": "sVP9ho_G3zKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the weights and the video to be processed"
      ],
      "metadata": {
        "id": "_XiCOsLt6lb7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set GPU Access: Edit->Notebook Setting->Hardware Accelerator->GPU->Save"
      ],
      "metadata": {
        "id": "TrzpVTbf63Tp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYChepfa3ps5"
      },
      "outputs": [],
      "source": [
        "#Checking access to GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "id": "nTynkob966mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the source path to the name of the uploaded video"
      ],
      "metadata": {
        "id": "38in175Z67Mq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SOURCE_VIDEO_PATH = f\"{HOME}/can_rolling.mp4\" #file name of the video to be processed"
      ],
      "metadata": {
        "id": "FvuVZ_EI7FBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install YOLOv8"
      ],
      "metadata": {
        "id": "rKGLV1CU7HZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip installing YOLOV8\n",
        "!pip install ultralytics==8.0.20\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "id": "ThiyX1rP7SZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install ByteTrack**"
      ],
      "metadata": {
        "id": "MiveC2ky8J_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/ifzhang/ByteTrack.git\n",
        "%cd {HOME}/ByteTrack\n",
        "\n",
        "!sed -i 's/onnx==1.8.1/onnx==1.9.0/g' requirements.txt\n",
        "\n",
        "#installing required dependencies\n",
        "!pip3 install -q -r requirements.txt\n",
        "!python3 setup.py -q develop\n",
        "!pip install -q cython_bbox\n",
        "!pip install -q onemetric\n",
        "!pip install yolox\n",
        "!pip install loguru\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append(f\"{HOME}/ByteTrack\")\n",
        "\n",
        "import yolox\n",
        "print(\"yolox.__version__:\", yolox.__version__)"
      ],
      "metadata": {
        "id": "kM3Mu1wf8Rbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lap\n",
        "from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
        "from onemetric.cv.utils.iou import box_iou_batch\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class BYTETrackerArgs:\n",
        "    track_thresh: float = 0.25\n",
        "    track_buffer: int = 30\n",
        "    match_thresh: float = 0.8\n",
        "    aspect_ratio_thresh: float = 3.0\n",
        "    min_box_area: float = 1.0\n",
        "    mot20: bool = False"
      ],
      "metadata": {
        "id": "FRukvDxC8VV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Roboflow Supervision"
      ],
      "metadata": {
        "id": "77m1aECQ8uTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supervision==0.1.0\n",
        "\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import supervision\n",
        "print(\"supervision.__version__:\", supervision.__version__)"
      ],
      "metadata": {
        "id": "rNBtLxYq8stW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from supervision.draw.color import ColorPalette\n",
        "from supervision.geometry.dataclasses import Point\n",
        "from supervision.video.dataclasses import VideoInfo\n",
        "from supervision.video.source import get_video_frames_generator\n",
        "from supervision.video.sink import VideoSink\n",
        "from supervision.notebook.utils import show_frame_in_notebook\n",
        "from supervision.tools.detections import Detections, BoxAnnotator\n",
        "from supervision.tools.line_counter import LineCounter, LineCounterAnnotator"
      ],
      "metadata": {
        "id": "-mGUBR798sqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tracking Utils"
      ],
      "metadata": {
        "id": "-d83NGRd89hX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# converts Detections into format that can be consumed by match_detections_with_tracks function\n",
        "def detections2boxes(detections: Detections) -> np.ndarray:\n",
        "    return np.hstack((\n",
        "        detections.xyxy,\n",
        "        detections.confidence[:, np.newaxis]\n",
        "    ))\n",
        "\n",
        "\n",
        "# converts List[STrack] into format that can be consumed by match_detections_with_tracks function\n",
        "def tracks2boxes(tracks: List[STrack]) -> np.ndarray:\n",
        "    return np.array([\n",
        "        track.tlbr\n",
        "        for track\n",
        "        in tracks\n",
        "    ], dtype=float)\n",
        "\n",
        "\n",
        "# matches our bounding boxes with predictions\n",
        "def match_detections_with_tracks(\n",
        "    detections: Detections,\n",
        "    tracks: List[STrack]\n",
        ") -> Detections:\n",
        "    if not np.any(detections.xyxy) or len(tracks) == 0:\n",
        "        return np.empty((0,))\n",
        "\n",
        "    tracks_boxes = tracks2boxes(tracks=tracks)\n",
        "    iou = box_iou_batch(tracks_boxes, detections.xyxy)\n",
        "    track2detection = np.argmax(iou, axis=1)\n",
        "\n",
        "    tracker_ids = [None] * len(detections)\n",
        "\n",
        "    for tracker_index, detection_index in enumerate(track2detection):\n",
        "        if iou[tracker_index, detection_index] != 0:\n",
        "            tracker_ids[detection_index] = tracks[tracker_index].track_id\n",
        "\n",
        "    return tracker_ids"
      ],
      "metadata": {
        "id": "hg8ob7pp8sm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the pretrained YOLOv8 model"
      ],
      "metadata": {
        "id": "LJtAdLa89Glw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the uploaded weights are unzipped\n",
        "%cd {HOME}\n",
        "!unzip weights.zip"
      ],
      "metadata": {
        "id": "FdB_rzI58skT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#assign the best weights to the MODEL\n",
        "MODEL = \"runs/detect/train/weights/best.pt\""
      ],
      "metadata": {
        "id": "PJdZy9ZY9a85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(MODEL)\n",
        "model.fuse()"
      ],
      "metadata": {
        "id": "27dtpIDt9a5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting and Annotating a single frame from the video"
      ],
      "metadata": {
        "id": "mZib7ehE9i6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mapping class_id to class_name\n",
        "CLASS_NAMES_DICT = model.model.names\n",
        "# class_ids of interest - bottles,cans,cigarettes\n",
        "CLASS_ID = [1, 2, 3]"
      ],
      "metadata": {
        "id": "GjMZsb_s9a2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# frame generator\n",
        "generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "# BoxAnnotator\n",
        "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2)\n",
        "# acquiring a frame\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "# predicting a single frame using the model\n",
        "results = model(frame)\n",
        "detections = Detections(\n",
        "    xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
        "    confidence=results[0].boxes.conf.cpu().numpy(),\n",
        "    class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
        ")\n",
        "# formatting the labels\n",
        "labels = [\n",
        "    f\"{CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
        "    for _, confidence, class_id, tracker_id\n",
        "    in detections\n",
        "]\n",
        "# annotating and displaying the frame\n",
        "frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
        "\n",
        "%matplotlib inline\n",
        "show_frame_in_notebook(frame, (16, 16))"
      ],
      "metadata": {
        "id": "wE85V1Mz9awO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting and Annotating the entire video"
      ],
      "metadata": {
        "id": "9B45zgax-vTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting the starting and ending points of the line counter as per the dimensions and the region of interest from the previous frame\n",
        "LINE_START = Point(600, 0)\n",
        "LINE_END = Point(3840-2840, 0)\n",
        "\n",
        "#set the name of the result file\n",
        "TARGET_VIDEO_PATH = f\"{HOME}/can-rollv1-result.mp4\""
      ],
      "metadata": {
        "id": "J21ZI-gL9atU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VideoInfo.from_video_path(SOURCE_VIDEO_PATH)"
      ],
      "metadata": {
        "id": "mIaPvuS5_MKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "# creating the BYTETracker instance\n",
        "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
        "# creating the VideoInfo instance\n",
        "video_info = VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "# creating the frame generator\n",
        "generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "# creating the LineCounter instance\n",
        "line_counter = LineCounter(start=LINE_START, end=LINE_END)\n",
        "# creating instances of BoxAnnotator and LineCounterAnnotator\n",
        "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2)\n",
        "line_annotator = LineCounterAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "\n",
        "# open target video file\n",
        "with VideoSink(TARGET_VIDEO_PATH, video_info) as sink:\n",
        "\n",
        "    for frame in tqdm(generator, total=video_info.total_frames):\n",
        "        results = model(frame)\n",
        "        detections = Detections(\n",
        "            xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
        "            confidence=results[0].boxes.conf.cpu().numpy(),\n",
        "            class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
        "        )\n",
        "        # filtering out unwanted classes\n",
        "        mask = np.array([class_id in CLASS_ID for class_id in detections.class_id], dtype=bool)\n",
        "        detections.filter(mask=mask, inplace=True)\n",
        "        # tracking detections\n",
        "        tracks = byte_tracker.update(\n",
        "            output_results=detections2boxes(detections=detections),\n",
        "            img_info=frame.shape,\n",
        "            img_size=frame.shape\n",
        "        )\n",
        "        tracker_id = match_detections_with_tracks(detections=detections, tracks=tracks)\n",
        "        detections.tracker_id = np.array(tracker_id)\n",
        "        mask = np.array([tracker_id is not None for tracker_id in detections.tracker_id], dtype=bool)\n",
        "        detections.filter(mask=mask, inplace=True)\n",
        "        labels = [\n",
        "            f\"#{tracker_id} {CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
        "            for _, confidence, class_id, tracker_id\n",
        "            in detections\n",
        "        ]\n",
        "        # updating the line counter\n",
        "        line_counter.update(detections=detections)\n",
        "        # annotating and displaying frame\n",
        "        frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
        "        line_annotator.annotate(frame=frame, line_counter=line_counter)\n",
        "        sink.write_frame(frame)\n",
        "        with open(\"output.txt\", \"w\") as file:\n",
        "            # Print the variable into the output file\n",
        "            print(detections, file=file)\n",
        "        sink.write_frame(frame)"
      ],
      "metadata": {
        "id": "zJ-90SmX_MqX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}